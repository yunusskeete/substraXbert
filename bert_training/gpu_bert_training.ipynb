{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MacOS version: 12.5.1 (>=12.3.X)\n",
      "Using: arm64 version of python ('arm64')\n",
      "GPU acceleration for torch: True\n",
      "Platform: macOS-12.5.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import platform\n",
    "\n",
    "mac_info = platform.mac_ver()\n",
    "print(f\"MacOS version: {mac_info[0]} (>=12.3.X)\")\n",
    "print(f\"Using: {mac_info[2]} version of python ('arm64')\")\n",
    "\n",
    "print(f\"GPU acceleration for torch: {torch.has_mps}\")\n",
    "\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardware acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunusskeete/Documents/substraXbert/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer # pip install transformers\n",
    "from datasets import load_dataset # pip install datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data to fine-tune the Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (/Users/yunusskeete/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'coarse_label', 'fine_label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the first 1K rows of the TREC dataset\n",
    "trec = load_dataset('trec', split='train[:1000]')\n",
    "trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (/Users/yunusskeete/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'coarse_label', 'fine_label'],\n",
       "    num_rows: 5452\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trecTRAIN = load_dataset('trec', split='train')\n",
    "trecTRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (/Users/yunusskeete/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'coarse_label', 'fine_label'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trecTEST = load_dataset('trec', split='test')\n",
    "trecTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'How did serfdom develop in and then leave Russia ?',\n",
       " 'coarse_label': 2,\n",
       " 'fine_label': 26}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (/Users/yunusskeete/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'coarse_label', 'fine_label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trec = load_dataset('trec', split='train[1000:1200]')\n",
    "test_trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'What singer became despondent over the death of Freddie Prinze , quit show business , and then quit the business ?',\n",
       " 'coarse_label': 3,\n",
       " 'fine_label': 29}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trec[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the bert-base-uncased tokenizer from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# we have a small dataset so we can tokenize everything at once\n",
    "# tokenize everything\n",
    "tokens = tokenizer(\n",
    "    trec['text'], max_length=512,\n",
    "    truncation=True, padding='max_length'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=512, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2129, 2106, 14262, 2546, 9527, 4503, 1999, 1998, 2059],\n",
       " [2681, 3607, 1029, 102, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0].ids[:10], tokens[0].ids[10:20], tokens[0].ids[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initialize array to be used\n",
    "labels = np.zeros(\n",
    "    (len(trec), max(trec['coarse_label'])+1)\n",
    ")\n",
    "# one-hot encode\n",
    "labels[np.arange(len(trec)), trec['coarse_label']] = 1\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize array to be used\n",
    "test_labels = np.zeros(\n",
    "    (len(trec), max(test_trec['coarse_label'])+1)\n",
    ")\n",
    "# one-hot encode\n",
    "test_labels[np.arange(len(test_trec)), test_trec['coarse_label']] = 1\n",
    "test_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.Tensor(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrecDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.tokens[idx].ids\n",
    "        attention_mask = self.tokens[idx].attention_mask\n",
    "        labels = self.labels[idx]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids),\n",
    "            'attention_mask': torch.tensor(attention_mask),\n",
    "            'labels': torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset = TrecDataset(tokens, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(trec['coarse_label'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "config.num_labels = max(trec['coarse_label'])+1\n",
    "model = BertForSequenceClassification(config).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fine-tune the classification head only:\n",
    "Freeze all BERT layer parameters, leaving just final few classification layers.\n",
    "\"\"\"\n",
    "\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunusskeete/Documents/substraXbert/venv/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# activate training mode of model\n",
    "model.train()\n",
    "\n",
    "# initialize adam optimizer with weight decay\n",
    "optim = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,614 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/var/folders/fr/fq874wcs1c9f075hr2q9_vrm0000gn/T/ipykernel_69940/3304426640.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(labels)\n",
      "100%|██████████| 16/16 [05:37<00:00, 21.07s/it, loss=0.623]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "loop_time = []\n",
    "\n",
    "# setup loop (using tqdm for the progress bar)\n",
    "loop = tqdm(loader, leave=True)\n",
    "for batch in loop:\n",
    "    batch_mps = {\n",
    "        'input_ids': batch['input_ids'].to(device),\n",
    "        'attention_mask': batch['attention_mask'].to(device),\n",
    "        'labels': batch['labels'].to(device)\n",
    "    }\n",
    "    t0 = time()\n",
    "    # initialize calculated gradients (from prev step)\n",
    "    optim.zero_grad()\n",
    "    # train model on batch and return outputs (incl. loss)\n",
    "    outputs = model(**batch_mps)\n",
    "    # extract loss\n",
    "    loss = outputs[0]\n",
    "    # calculate loss for every parameter that needs grad update\n",
    "    loss.backward()\n",
    "    # update parameters\n",
    "    optim.step()\n",
    "    loop_time.append(time()-t0)\n",
    "    # print relevant info to progress bar\n",
    "    loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.102845907211304,\n",
       " 17.658621788024902,\n",
       " 17.239214181900024,\n",
       " 18.1284282207489,\n",
       " 16.0555682182312,\n",
       " 16.633388996124268,\n",
       " 16.169923067092896,\n",
       " 17.234124660491943,\n",
       " 20.20867419242859,\n",
       " 15.843982934951782,\n",
       " 16.44768500328064,\n",
       " 16.141244888305664,\n",
       " 17.065425872802734,\n",
       " 17.40112614631653,\n",
       " 17.688358068466187,\n",
       " 11.527345895767212]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/var/folders/fr/fq874wcs1c9f075hr2q9_vrm0000gn/T/ipykernel_69940/3304426640.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'labels': torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "# Put model into inference mode\n",
    "model.eval()\n",
    "\n",
    "predictions = torch.Tensor([]).to(device)\n",
    "\n",
    "test_loop = tqdm(test_loader, leave=True)\n",
    "with torch.inference_mode():\n",
    "    for batch in loop:\n",
    "        batch_mps = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        outputs = model(**batch_mps)\n",
    "        preds = outputs['logits']\n",
    "        predictions = torch.cat((predictions, preds), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunusskeete/Documents/substraXbert/venv/lib/python3.9/site-packages/torch/_tensor_str.py:115: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:218.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 6]),\n",
       " tensor([-0.2157, -0.2370, -0.5152, -0.2934, -0.3427, -0.3002], device='mps:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape, predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# predictions_path = \"./predictions\"\n",
    "# if not os.path.isdir(predictions_path):\n",
    "#     os.mkdir(predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# if predictions_path is not None:\n",
    "#     np.save(predictions_path, predictions.cpu())\n",
    "\n",
    "#     # np.save() automatically adds a \".npy\" to the end of the file.\n",
    "#     # We rename the file produced by removing the \".npy\" suffix, to make sure that\n",
    "#     # predictions_path is the actual file name.\n",
    "#     shutil.move(str(predictions_path) + \".npy\", predictions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2043, 2024,  ...,    0,    0,    0],\n",
       "         [ 101, 2054, 4368,  ...,    0,    0,    0],\n",
       "         [ 101, 2054, 1005,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2054, 2003,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 2001,  ...,    0,    0,    0],\n",
       "         [ 101, 2040, 6791,  ...,    0,    0,    0]], device='mps:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='mps:0'),\n",
       " 'labels': tensor([[0., 0., 0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.]], device='mps:0')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(**batch_mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6254, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss1 = outputs.loss\n",
    "loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0620, -0.3503, -0.4045, -0.5189, -0.1923, -0.2770],\n",
       "        [-0.0178, -0.3267, -0.3746, -0.4427, -0.0427, -0.2308],\n",
       "        [-0.0063, -0.3166, -0.3543, -0.5956, -0.1608, -0.2279],\n",
       "        [-0.0798, -0.2898, -0.4046, -0.5222, -0.1880, -0.1868],\n",
       "        [-0.0315, -0.3010, -0.4243, -0.5649, -0.1909, -0.2784],\n",
       "        [-0.0820, -0.3003, -0.4113, -0.5401, -0.2080, -0.2435],\n",
       "        [-0.0761, -0.2901, -0.3044, -0.4977, -0.1462, -0.1609],\n",
       "        [ 0.0726, -0.3795, -0.3404, -0.4921, -0.1503, -0.2429],\n",
       "        [ 0.0619, -0.4194, -0.3907, -0.5288, -0.1095, -0.2095],\n",
       "        [-0.0349, -0.3293, -0.3984, -0.5432, -0.1490, -0.2525],\n",
       "        [ 0.0435, -0.3904, -0.4238, -0.4881, -0.1842, -0.2638],\n",
       "        [-0.1001, -0.3654, -0.3491, -0.4803, -0.0830, -0.2231],\n",
       "        [-0.0947, -0.3699, -0.5199, -0.4874, -0.2117, -0.2825],\n",
       "        [-0.0128, -0.3408, -0.4053, -0.4398, -0.1687, -0.3006],\n",
       "        [-0.0511, -0.3068, -0.2931, -0.5864, -0.1528, -0.2455],\n",
       "        [-0.0140, -0.3418, -0.3584, -0.5205, -0.1782, -0.2488],\n",
       "        [ 0.0210, -0.3126, -0.3696, -0.5746, -0.1799, -0.2439],\n",
       "        [-0.0112, -0.2953, -0.3473, -0.4777, -0.1115, -0.1851],\n",
       "        [ 0.0204, -0.3448, -0.3178, -0.5058, -0.0801, -0.1578],\n",
       "        [-0.0902, -0.4091, -0.3909, -0.4864, -0.1177, -0.2540],\n",
       "        [-0.0321, -0.3943, -0.4446, -0.5148, -0.2083, -0.3242],\n",
       "        [-0.0306, -0.3004, -0.4206, -0.5051, -0.1320, -0.2252],\n",
       "        [-0.0167, -0.4019, -0.3028, -0.4404, -0.1295, -0.2229],\n",
       "        [-0.0538, -0.3357, -0.4058, -0.4724, -0.1869, -0.2327],\n",
       "        [-0.0081, -0.3334, -0.4109, -0.5241, -0.1155, -0.1838],\n",
       "        [-0.0468, -0.3051, -0.4019, -0.5450, -0.1246, -0.1596],\n",
       "        [-0.0667, -0.3384, -0.4869, -0.5356, -0.1676, -0.2598],\n",
       "        [ 0.0230, -0.3300, -0.3798, -0.5142, -0.1072, -0.2513],\n",
       "        [-0.0134, -0.3500, -0.3626, -0.4215, -0.0766, -0.1795],\n",
       "        [ 0.0021, -0.3106, -0.4147, -0.4887, -0.1115, -0.1622],\n",
       "        [-0.0645, -0.3331, -0.3918, -0.4852, -0.1429, -0.2505],\n",
       "        [-0.0376, -0.3680, -0.3257, -0.5070, -0.0993, -0.2333],\n",
       "        [-0.0087, -0.3680, -0.3404, -0.5603, -0.1169, -0.2153],\n",
       "        [-0.0445, -0.3224, -0.3337, -0.5312, -0.1636, -0.1477],\n",
       "        [-0.0355, -0.3451, -0.4060, -0.5451, -0.1184, -0.2957],\n",
       "        [-0.0129, -0.3941, -0.3126, -0.5369, -0.1852, -0.1921],\n",
       "        [-0.0670, -0.2779, -0.4520, -0.4541, -0.1654, -0.2416],\n",
       "        [-0.0627, -0.3442, -0.4116, -0.4602, -0.0995, -0.2600],\n",
       "        [-0.0100, -0.3435, -0.3845, -0.5341, -0.1373, -0.2115],\n",
       "        [-0.0019, -0.3264, -0.4450, -0.5356, -0.1636, -0.2472],\n",
       "        [-0.0649, -0.3492, -0.4000, -0.4823, -0.1517, -0.2290],\n",
       "        [ 0.0298, -0.3097, -0.4077, -0.5290, -0.1512, -0.3052],\n",
       "        [-0.0416, -0.3808, -0.3959, -0.4598, -0.1364, -0.3118],\n",
       "        [-0.0109, -0.3348, -0.3764, -0.4825, -0.0749, -0.2616],\n",
       "        [-0.0218, -0.3267, -0.3419, -0.5768, -0.1076, -0.2870],\n",
       "        [ 0.0168, -0.2926, -0.3857, -0.4972, -0.1351, -0.2138],\n",
       "        [-0.0113, -0.3533, -0.3672, -0.5485, -0.0863, -0.2059],\n",
       "        [-0.0335, -0.3438, -0.3938, -0.4582, -0.1007, -0.2661],\n",
       "        [-0.0087, -0.4012, -0.3326, -0.5503, -0.1848, -0.2450],\n",
       "        [-0.0246, -0.3372, -0.3829, -0.4959, -0.1624, -0.2113],\n",
       "        [-0.0555, -0.3298, -0.3754, -0.5296, -0.1291, -0.1701],\n",
       "        [ 0.0749, -0.3414, -0.3452, -0.5218, -0.1479, -0.2919],\n",
       "        [-0.0261, -0.3875, -0.5053, -0.4923, -0.1141, -0.2465],\n",
       "        [ 0.0127, -0.3735, -0.3681, -0.4855, -0.1038, -0.2265],\n",
       "        [-0.0166, -0.3175, -0.3826, -0.4609, -0.1248, -0.1769],\n",
       "        [-0.0049, -0.3850, -0.4860, -0.5283, -0.1705, -0.2591],\n",
       "        [-0.0074, -0.3225, -0.3931, -0.4908, -0.2202, -0.2196],\n",
       "        [ 0.0154, -0.3147, -0.3927, -0.4909, -0.0938, -0.2145],\n",
       "        [ 0.0122, -0.3841, -0.3745, -0.4985, -0.2123, -0.2571],\n",
       "        [ 0.0220, -0.3807, -0.3682, -0.4931, -0.1154, -0.3012],\n",
       "        [ 0.0359, -0.4576, -0.3737, -0.4876, -0.0966, -0.2941],\n",
       "        [-0.0208, -0.2859, -0.2979, -0.5555, -0.1064, -0.1476],\n",
       "        [ 0.0093, -0.3388, -0.3690, -0.4933, -0.1102, -0.1798],\n",
       "        [ 0.1337, -0.3987, -0.3504, -0.5123, -0.1222, -0.2719]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8004, device='mps:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = criterion(outputs.logits, batch_mps['labels'])\n",
    "loss2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def accuracy(datasamples, predictions_path):\n",
    "\n",
    "    outputs = np.load(predictions_path)\n",
    "    labels = datasamples[\"labels\"]\n",
    "\n",
    "    preds = np.argmax(outputs, axis=1)\n",
    "\n",
    "    # I don't think we need to one-hot encode labels AT ALL\n",
    "\n",
    "    targets = np.argmax(labels, axis=1)\n",
    "    correct = preds == targets\n",
    "    acc = sum(correct) / len(correct)\n",
    "    \n",
    "    return acc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "\n",
    "    preds = np.argmax(outputs, axis=1)\n",
    "\n",
    "    # I don't think we need to one-hot encode labels AT ALL\n",
    "\n",
    "    targets = np.argmax(labels, axis=1)\n",
    "    correct = preds == targets\n",
    "    acc = sum(correct) / len(correct)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.argmax(outputs.logits.cpu().detach(), axis=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 4, 2, 5, 1, 5, 1, 1, 1, 1, 4, 2, 3, 3, 3, 5, 1, 3, 5, 0, 2, 4, 2,\n",
       "        1, 5, 3, 1, 3, 2, 4, 1, 1, 1, 1, 2, 4, 2, 3, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.argmax(batch_mps['labels'].cpu().detach(), axis=1)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0250)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy(outputs.logits.cpu().detach(), batch_mps['labels'].cpu().detach())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Evaluating function\n",
    "# *******************\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    \n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    \n",
    "    # activate evaluation mode of model\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in tqdm(test_loader, leave=None):\n",
    "\n",
    "        batch_mps = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "                \n",
    "        outputs = model(**batch_mps)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        # loss = criterion(outputs.logits, batch_mps[\"labels\"])\n",
    "        acc = accuracy(outputs.logits.cpu().detach(), batch_mps['labels'].cpu().detach())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
